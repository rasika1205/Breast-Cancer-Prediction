{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82734720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn core tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e1d36",
   "metadata": {},
   "source": [
    "### Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ebd863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\rasik\\Downloads\\BreastCancerpredictionProject\\breast-cancer-data.csv\")\n",
    "\n",
    "# Show first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be50d97",
   "metadata": {},
   "source": [
    "### Distribution of Diagnosis\n",
    "This helps us to understand class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c85cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    62.741652\n",
       "M    37.258348\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6e519",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "- The data is roughly balanced between malignant and benign.\n",
    "- No sampling needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68b66c",
   "metadata": {},
   "source": [
    "### Encode Labels\n",
    "Convert 'M' (Malignant) to 1 and 'B' (Benign) to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df38b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d48f7",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Separate predictors and target, then split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e929c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['id', 'diagnosis','Unnamed: 32'])\n",
    "y = df['diagnosis'].values\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c72a90",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "Scale features to have mean 0 and variance 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95422155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2146f",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "We apply:\n",
    "- RFE (Recursive Feature Elimination)\n",
    "- PCA (Principal Component Analysis)\n",
    "- Kernel PCA\n",
    "- LDA (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1a0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4506074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RFE Selected Features:\n",
      "['concavity_mean' 'concave points_mean' 'radius_se' 'perimeter_se'\n",
      " 'area_se' 'compactness_se' 'fractal_dimension_se' 'radius_worst'\n",
      " 'texture_worst' 'perimeter_worst' 'area_worst' 'concavity_worst'\n",
      " 'concave points_worst' 'symmetry_worst' 'fractal_dimension_worst']\n",
      "\n",
      "=== RFE (15 features) ===\n",
      "Confusion Matrix:\n",
      "[[65  2]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.97      0.96        67\n",
      "      Benign       0.96      0.94      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== PCA (10 components) ===\n",
      "Confusion Matrix:\n",
      "[[64  3]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.96      0.96        67\n",
      "      Benign       0.94      0.94      0.94        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "\n",
      "=== Kernel PCA (10 components) ===\n",
      "Confusion Matrix:\n",
      "[[67  0]\n",
      " [ 4 43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.94      1.00      0.97        67\n",
      "      Benign       1.00      0.91      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== LDA (1 component) ===\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 2 45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.99      0.98        67\n",
      "      Benign       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "\n",
    "def train_and_report(X_train, X_test, y_train, y_test, description):\n",
    "    \"\"\"\n",
    "    Train logistic regression and print evaluation metrics.\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n=== {description} ===\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Malignant\", \"Benign\"]))\n",
    "# 1. RFE\n",
    "rfe_selector = RFE(LogisticRegression(max_iter=1000), n_features_to_select=15)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "X_train_rfe = rfe_selector.transform(X_train)\n",
    "X_test_rfe = rfe_selector.transform(X_test)\n",
    "\n",
    "selected_features = np.array(feature_names)[rfe_selector.get_support()]\n",
    "print(\"\\nRFE Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "train_and_report(X_train_rfe, X_test_rfe, y_train, y_test, \"RFE (15 features)\")\n",
    "\n",
    "# 2. PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "train_and_report(X_train_pca, X_test_pca, y_train, y_test, \"PCA (10 components)\")\n",
    "\n",
    "# 3. Kernel PCA\n",
    "kpca = KernelPCA(n_components=10, kernel=\"rbf\")\n",
    "X_train_kpca = kpca.fit_transform(X_train)\n",
    "X_test_kpca = kpca.transform(X_test)\n",
    "\n",
    "train_and_report(X_train_kpca, X_test_kpca, y_train, y_test, \"Kernel PCA (10 components)\")\n",
    "\n",
    "# 4. LDA\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "train_and_report(X_train_lda, X_test_lda, y_train, y_test, \"LDA (1 component)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f7e5c",
   "metadata": {},
   "source": [
    "✅ Malignant Recall priority:\n",
    "\n",
    "1. Kernel PCA (1.00)\n",
    "\n",
    "2. LDA (0.99)\n",
    "\n",
    "3. RFE (0.97)\n",
    "\n",
    "4. PCA (0.96)\n",
    "\n",
    "✅ Overall balance (Recall + Precision + Accuracy):\n",
    "\n",
    "LDA has the best trade-off:\n",
    "\n",
    "1. Very high recall (0.99)\n",
    "\n",
    "2. Very high precision (0.97)\n",
    "\n",
    "3. Highest overall accuracy (0.97)\n",
    "\n",
    "4. Lowest false positives (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8af4b",
   "metadata": {},
   "source": [
    "### Model Comparison on LDA Features\n",
    "We train multiple classifiers to find the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24ec382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 2 45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.99      0.98        67\n",
      "      Benign       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Confusion Matrix:\n",
      "[[65  2]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.97      0.96        67\n",
      "      Benign       0.96      0.94      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== Decision Tree ===\n",
      "Confusion Matrix:\n",
      "[[65  2]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.97      0.96        67\n",
      "      Benign       0.96      0.94      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== SVM ===\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 2 45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.99      0.98        67\n",
      "      Benign       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "=== KNN ===\n",
      "Confusion Matrix:\n",
      "[[65  2]\n",
      " [ 2 45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.97      0.97        67\n",
      "      Benign       0.96      0.96      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== Naive Bayes ===\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.99      0.97        67\n",
      "      Benign       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=500),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=[\"Malignant\", \"Benign\"]))\n",
    "evaluate_models(X_train_lda, X_test_lda, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3669a",
   "metadata": {},
   "source": [
    "✅ Logistic Regression and SVM are clear standouts:\n",
    "\n",
    "- Recall 0.99 on malignant (missed only 1 case)\n",
    "\n",
    "- Very high precision and F1\n",
    "\n",
    "- Highest accuracy (0.97)\n",
    "\n",
    "✅ Naive Bayes also very good but slightly more false positives (lower Benign recall).\n",
    "\n",
    "✅ KNN, Random Forest, Decision Tree had:\n",
    "\n",
    "- Recall 0.97 (missed 2 cancer cases instead of 1)\n",
    "\n",
    "- Slightly lower metrics overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed12f0",
   "metadata": {},
   "source": [
    "### Boosting Models on RFE Features\n",
    "We also test ensemble methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72de60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AdaBoost ===\n",
      "Confusion Matrix:\n",
      "[[64  3]\n",
      " [ 2 45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.96      0.96        67\n",
      "      Benign       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Confusion Matrix:\n",
      "[[64  3]\n",
      " [ 3 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.96      0.96      0.96        67\n",
      "      Benign       0.94      0.94      0.94        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Confusion Matrix:\n",
      "[[63  4]\n",
      " [ 0 47]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       1.00      0.94      0.97        67\n",
      "      Benign       0.92      1.00      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rasik\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\training.py:183: UserWarning: [10:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_boosting_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=[\"Malignant\", \"Benign\"]))\n",
    "evaluate_boosting_models(X_train_rfe, X_test_rfe, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b229e",
   "metadata": {},
   "source": [
    "✅ XGBoost Highlights:\n",
    "\n",
    "- Benign Recall = 1.00 (no false negatives on benign)\n",
    "\n",
    "- Malignant Recall = 0.94 (missed 4 cancer cases)\n",
    "⚠️ This is lower than Logistic Regression (0.97) and SVM (0.97).\n",
    "\n",
    "- High overall accuracy, but recall on malignant is the most important metric here.\n",
    "\n",
    "✅ AdaBoost:\n",
    "\n",
    "- Almost identical to Random Forest and Logistic Regression.\n",
    "\n",
    "- Malignant Recall 0.96\n",
    "\n",
    "- Accuracy 0.96\n",
    "\n",
    "✅ Gradient Boosting:\n",
    "\n",
    "- Malignant Recall 0.96\n",
    "\n",
    "- Slightly lower accuracy (0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c194db",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Logistic Regression\n",
    "We fine-tune Logistic Regression using Grid Search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c6fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best Parameters:\n",
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  1]\n",
      " [ 2 45]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.99      0.98        67\n",
      "      Benign       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_lda, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "y_pred = best_log_reg.predict(X_test_lda)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Malignant\", \"Benign\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5158b",
   "metadata": {},
   "source": [
    "### Save Models and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a333b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save scaler, LDA, and final model\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sc, f)\n",
    "\n",
    "with open(\"lda.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lda, f)\n",
    "\n",
    "with open(\"logistic_regression_best.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_log_reg, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (TensorFlow)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
